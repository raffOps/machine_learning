{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from typing import Any\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.Kfold.kfold import Kfold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_random_combinations_of_parameters(\n",
    "        parameters: dict,\n",
    "        number_of_combinations: int\n",
    ") -> list[int]:\n",
    "    combinations = []\n",
    "    for _ in range(number_of_combinations):\n",
    "        combination = {}\n",
    "        for parameter, values in parameters.items():\n",
    "            combination[parameter] = random.choice(values)\n",
    "        combinations.append(combination)\n",
    "    return combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random.seed(44)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def get_best_parameters(\n",
    "        classifier: Any,\n",
    "        parameters_grid: dict[str, Any],\n",
    "        numbers_of_folds: int,\n",
    "        number_of_parameters_combinations: int,\n",
    "        values: tuple[np.ndarray, np.ndarray]\n",
    ") -> tuple[dict[str, Any], pd.DataFrame]:\n",
    "    grid_results = []\n",
    "    parameters_combinations = get_random_combinations_of_parameters(\n",
    "        parameters_grid,\n",
    "        number_of_parameters_combinations\n",
    "    )\n",
    "    X, y = values\n",
    "    for combination in parameters_combinations:\n",
    "        tunning_kfold = Kfold(numbers_of_folds)\n",
    "        times = []\n",
    "        scores = []\n",
    "        for (\n",
    "            x_train_tunning,\n",
    "            x_test_tunning,\n",
    "            y_train_tunning,\n",
    "            y_test_tunning\n",
    "        ) in tunning_kfold.split(X, y):\n",
    "            initial_time = time()\n",
    "            cls = classifier(**combination)\n",
    "            cls.fit(x_train_tunning, y_train_tunning)\n",
    "            final_time = time()\n",
    "            times.append(final_time-initial_time)\n",
    "            predictions = cls.predict(x_test_tunning)\n",
    "            score = f1_score(y_test_tunning, predictions)\n",
    "            scores.append(score)\n",
    "        mean_time = np.asarray(times).mean()\n",
    "        scores = np.asarray(scores)\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        grid_results.append(\n",
    "            dict(combination, f1_mean_score=mean_score, f1_score_std=std_score, mean_time=mean_time)\n",
    "        )\n",
    "    grid_results = pd.DataFrame(grid_results).sort_values(\n",
    "        by=[\"f1_mean_score\"],\n",
    "        ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    best_parameters = grid_results.iloc[:,:-3].to_dict(\"records\")[0]\n",
    "\n",
    "    return best_parameters, grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<class 'sklearn.ensemble._forest.RandomForestClassifier'>\""
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(RandomForestClassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def run_cross_validation(\n",
    "        classifier: Any,\n",
    "        parameters_grid: dict[str, Any],\n",
    "        number_of_parameters_combinations: int,\n",
    "        numbers_of_folds: int,\n",
    "        values: tuple[np.ndarray, np.ndarray]\n",
    ") -> tuple[dict[str, Any], pd.DataFrame, Any]:\n",
    "    validation_kfold = Kfold(k=numbers_of_folds)\n",
    "    X, y = values\n",
    "    scores = []\n",
    "    for (\n",
    "        x_train_validation,\n",
    "        x_test_validation,\n",
    "        y_train_validation,\n",
    "        y_test_validation\n",
    "    ) in validation_kfold.split(X, y):\n",
    "        best_parameters, tunning_results = get_best_parameters(\n",
    "            classifier=classifier,\n",
    "            parameters_grid=parameters_grid,\n",
    "            numbers_of_folds=numbers_of_folds-1,\n",
    "            number_of_parameters_combinations=number_of_parameters_combinations,\n",
    "            values=(x_train_validation, y_train_validation)\n",
    "        )\n",
    "        tunning_results.to_csv(\"../data/results/random_search_tunning_results.csv\")\n",
    "        print(f\"classifier: {classifier}\\nbest parameters: {best_parameters}\")\n",
    "\n",
    "        cls = classifier(**best_parameters)\n",
    "        cls.fit(x_train_validation, y_train_validation)\n",
    "        predictions = cls.predict(x_test_validation)\n",
    "        score = f1_score(y_test_validation, predictions)\n",
    "        scores.append(score)\n",
    "    scores = np.asarray(scores)\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "\n",
    "    return mean_score, std_score, cls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"../data/winequality-red.csv\", sep=\";\")\n",
    "    y = df.quality.apply(lambda quality: 0 if quality <= 5 else 1)\n",
    "    X =  MinMaxScaler().fit_transform(df.iloc[:,:-1])\n",
    "    number_of_parameters_combinations = 10\n",
    "    number_of_folds = 10\n",
    "\n",
    "    parameters_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 300],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.2, None]\n",
    "    }\n",
    "\n",
    "    run_cross_validation(\n",
    "        classifier=RandomForestClassifier,\n",
    "        parameters_grid=parameters_grid,\n",
    "        number_of_parameters_combinations=number_of_parameters_combinations,\n",
    "        numbers_of_folds=number_of_folds,\n",
    "        values=(X, y)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'take'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [74]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [73]\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m number_of_folds \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m      8\u001B[0m parameters_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m300\u001B[39m],\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcriterion\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgini\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_features\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msqrt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m     12\u001B[0m }\n\u001B[0;32m---> 14\u001B[0m \u001B[43mrun_cross_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRandomForestClassifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameters_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters_grid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumber_of_parameters_combinations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_parameters_combinations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumbers_of_folds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_folds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [72]\u001B[0m, in \u001B[0;36mrun_cross_validation\u001B[0;34m(classifier, parameters_grid, number_of_parameters_combinations, numbers_of_folds, values)\u001B[0m\n\u001B[1;32m     10\u001B[0m scores \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[1;32m     12\u001B[0m     x_train_validation,\n\u001B[1;32m     13\u001B[0m     x_test_validation,\n\u001B[1;32m     14\u001B[0m     y_train_validation,\n\u001B[1;32m     15\u001B[0m     y_test_validation\n\u001B[1;32m     16\u001B[0m ) \u001B[38;5;129;01min\u001B[39;00m validation_kfold\u001B[38;5;241m.\u001B[39msplit(X, y):\n\u001B[0;32m---> 17\u001B[0m     best_parameters, tunning_results \u001B[38;5;241m=\u001B[39m \u001B[43mget_best_parameters\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclassifier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters_grid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumbers_of_folds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumbers_of_folds\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumber_of_parameters_combinations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_parameters_combinations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_train_validation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_validation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     tunning_results\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/results/random_search_tunning_results.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassifier: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassifier\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mbest parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_parameters\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[0;32mIn [65]\u001B[0m, in \u001B[0;36mget_best_parameters\u001B[0;34m(classifier, parameters_grid, numbers_of_folds, number_of_parameters_combinations, values)\u001B[0m\n\u001B[1;32m     16\u001B[0m times \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     17\u001B[0m scores \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[1;32m     19\u001B[0m     x_train_tunning,\n\u001B[1;32m     20\u001B[0m     x_test_tunning,\n\u001B[1;32m     21\u001B[0m     y_train_tunning,\n\u001B[1;32m     22\u001B[0m     y_test_tunning\n\u001B[1;32m     23\u001B[0m ) \u001B[38;5;129;01min\u001B[39;00m tunning_kfold\u001B[38;5;241m.\u001B[39msplit(X, y):\n\u001B[1;32m     24\u001B[0m     initial_time \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m classifier(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcombination)\n",
      "File \u001B[0;32m~/src/Kfold/kfold.py:54\u001B[0m, in \u001B[0;36mKfold.split\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m     52\u001B[0m y_train \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index \u001B[38;5;129;01min\u001B[39;00m train_indexes_folds:\n\u001B[0;32m---> 54\u001B[0m     x_train\u001B[38;5;241m.\u001B[39mextend(\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m(folds[train_index], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     55\u001B[0m     y_train\u001B[38;5;241m.\u001B[39mextend(y\u001B[38;5;241m.\u001B[39mtake(folds[train_index], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     56\u001B[0m x_test \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mtake(folds[test_index_fold], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'take'"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}