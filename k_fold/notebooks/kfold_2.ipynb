{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from typing import Any\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.Kfold.kfold import Kfold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/winequality-red.csv\", sep=\";\")\n",
    "y = df.quality.apply(lambda quality: 0 if quality <= 5 else 1)\n",
    "X =  MinMaxScaler().fit_transform(df.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_random_combinations_of_parameters(\n",
    "        parameters: dict,\n",
    "        number_of_combinations: int\n",
    ") -> list[int]:\n",
    "    combinations = []\n",
    "    for _ in range(number_of_combinations):\n",
    "        combination = {}\n",
    "        for parameter, values in parameters.items():\n",
    "            combination[parameter] = random.choice(values)\n",
    "        combinations.append(combination)\n",
    "    return combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "K = 10\n",
    "validation_kfold = Kfold(K)\n",
    "for (x_train_validation,\n",
    "     x_test_validation,\n",
    "     y_train_validation,\n",
    "     y_test_validation) in validation_kfold.split(X, y):\n",
    "    tunning_kfold = Kfold(K-1)\n",
    "    for (x_train_tunning,\n",
    "         x_test_tunning,\n",
    "         y_train_tunning,\n",
    "         y_test_tunning) in tunning_kfold.split(x_train_validation, y_train_validation):\n",
    "        parameters_combinations = get_random_combinations_of_parameters(\n",
    "            random_forest_parameters_grid,\n",
    "            20\n",
    "        )\n",
    "        for combination in parameters_combinations:\n",
    "            inicial_time = time()\n",
    "            cls = RandomForestClassifier(**parameters_combinations)\n",
    "            final_time = time()\n",
    "            cls.fit(x_train_tunning, y_train_tunning)\n",
    "            predictions = cls.predict(x_test_tunning)\n",
    "            score = f1_score(y_test_tunning, predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random.seed(44)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "a = Kfold(3)\n",
    "a = list(a.split(X, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "cls = RandomForestClassifier\n",
    "parameters_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 300],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.2, None]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "abc.ABCMeta"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(RandomForestClassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def get_best_parameters(\n",
    "        classifier: Any,\n",
    "        parameters_grid: dict[str, Any],\n",
    "        numbers_of_folds: int,\n",
    "        number_of_parameters_combinations: int\n",
    ") -> tuple[dict[str, Any], pd.DataFrame]:\n",
    "    grid_results = []\n",
    "    parameters_combinations = get_random_combinations_of_parameters(\n",
    "        parameters_grid,\n",
    "        number_of_parameters_combinations\n",
    "    )\n",
    "    for combination in parameters_combinations:\n",
    "        tunning_kfold = Kfold(numbers_of_folds)\n",
    "        times = []\n",
    "        scores = []\n",
    "        for (\n",
    "            x_train_tunning,\n",
    "            x_test_tunning,\n",
    "            y_train_tunning,\n",
    "            y_test_tunning\n",
    "        ) in tunning_kfold.split(X, y):\n",
    "            initial_time = time()\n",
    "            cls = classifier(**combination)\n",
    "            cls.fit(x_train_tunning, y_train_tunning)\n",
    "            final_time = time()\n",
    "            times.append(final_time-initial_time)\n",
    "            predictions = cls.predict(x_test_tunning)\n",
    "            score = f1_score(y_test_tunning, predictions)\n",
    "            scores.append(score)\n",
    "        mean_time = np.asarray(times).mean()\n",
    "        scores = np.asarray(scores)\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        grid_results.append(\n",
    "            dict(combination, f1_mean_score=mean_score, f1_score_std=std_score, mean_time=mean_time)\n",
    "        )\n",
    "    grid_results = pd.DataFrame(grid_results).sort_values(\n",
    "        by=[\"f1_mean_score\"],\n",
    "        ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    best_parameters = grid_results.iloc[:,:-3].to_dict(\"records\")[0]\n",
    "\n",
    "    return best_parameters, grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 300],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.2, None]\n",
    "}\n",
    "random_forest_best_parameters, random_forest_tunning_results = get_best_parameters(\n",
    "    classifier=RandomForestClassifier,\n",
    "    parameters_grid=parameters_grid,\n",
    "    numbers_of_folds=10,\n",
    "    number_of_parameters_combinations=20\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 100, 'criterion': 'log_loss', 'max_features': 'sqrt'}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_tunning_results.to_csv(\"../data/results/random_search_tunning_results.csv\")\n",
    "random_forest_best_parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "    n_estimators criterion max_features  f1_mean_score  f1_score_std  \\\n0            100  log_loss         sqrt       0.832097      0.032340   \n1            100      gini          0.2       0.823526      0.032258   \n2            300   entropy         log2       0.823058      0.037372   \n3             50  log_loss         sqrt       0.820718      0.029076   \n4            300      gini          0.2       0.819135      0.018461   \n5            100  log_loss         sqrt       0.818911      0.029855   \n6            300  log_loss         log2       0.818422      0.021643   \n7            300      gini         sqrt       0.817021      0.032035   \n8            100   entropy         sqrt       0.815382      0.045687   \n9            300  log_loss         log2       0.815374      0.028283   \n10           300      gini         None       0.815345      0.027861   \n11           100      gini         sqrt       0.813840      0.033050   \n12           100      gini         sqrt       0.812152      0.038233   \n13           100      gini         log2       0.811310      0.020264   \n14           100   entropy          0.2       0.809896      0.038508   \n15            50  log_loss         None       0.807649      0.012860   \n16            10      gini         None       0.798347      0.047012   \n17           100      gini         None       0.795256      0.027589   \n18            10   entropy          0.2       0.794251      0.030931   \n19            10      gini         sqrt       0.787982      0.030690   \n\n    mean_time  \n0    0.292921  \n1    0.212535  \n2    0.777337  \n3    0.128911  \n4    0.612387  \n5    0.271351  \n6    0.766953  \n7    0.676975  \n8    0.257471  \n9    0.782174  \n10   1.578011  \n11   0.251487  \n12   0.285770  \n13   0.325622  \n14   0.230053  \n15   0.273507  \n16   0.048042  \n17   0.477009  \n18   0.022201  \n19   0.022901  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>criterion</th>\n      <th>max_features</th>\n      <th>f1_mean_score</th>\n      <th>f1_score_std</th>\n      <th>mean_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>0.832097</td>\n      <td>0.032340</td>\n      <td>0.292921</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>gini</td>\n      <td>0.2</td>\n      <td>0.823526</td>\n      <td>0.032258</td>\n      <td>0.212535</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300</td>\n      <td>entropy</td>\n      <td>log2</td>\n      <td>0.823058</td>\n      <td>0.037372</td>\n      <td>0.777337</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>0.820718</td>\n      <td>0.029076</td>\n      <td>0.128911</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>300</td>\n      <td>gini</td>\n      <td>0.2</td>\n      <td>0.819135</td>\n      <td>0.018461</td>\n      <td>0.612387</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100</td>\n      <td>log_loss</td>\n      <td>sqrt</td>\n      <td>0.818911</td>\n      <td>0.029855</td>\n      <td>0.271351</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>300</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>0.818422</td>\n      <td>0.021643</td>\n      <td>0.766953</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>300</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>0.817021</td>\n      <td>0.032035</td>\n      <td>0.676975</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>entropy</td>\n      <td>sqrt</td>\n      <td>0.815382</td>\n      <td>0.045687</td>\n      <td>0.257471</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>300</td>\n      <td>log_loss</td>\n      <td>log2</td>\n      <td>0.815374</td>\n      <td>0.028283</td>\n      <td>0.782174</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>300</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>0.815345</td>\n      <td>0.027861</td>\n      <td>1.578011</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>0.813840</td>\n      <td>0.033050</td>\n      <td>0.251487</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>100</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>0.812152</td>\n      <td>0.038233</td>\n      <td>0.285770</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100</td>\n      <td>gini</td>\n      <td>log2</td>\n      <td>0.811310</td>\n      <td>0.020264</td>\n      <td>0.325622</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100</td>\n      <td>entropy</td>\n      <td>0.2</td>\n      <td>0.809896</td>\n      <td>0.038508</td>\n      <td>0.230053</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>50</td>\n      <td>log_loss</td>\n      <td>None</td>\n      <td>0.807649</td>\n      <td>0.012860</td>\n      <td>0.273507</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>0.798347</td>\n      <td>0.047012</td>\n      <td>0.048042</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>100</td>\n      <td>gini</td>\n      <td>None</td>\n      <td>0.795256</td>\n      <td>0.027589</td>\n      <td>0.477009</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10</td>\n      <td>entropy</td>\n      <td>0.2</td>\n      <td>0.794251</td>\n      <td>0.030931</td>\n      <td>0.022201</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>gini</td>\n      <td>sqrt</td>\n      <td>0.787982</td>\n      <td>0.030690</td>\n      <td>0.022901</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_tunning_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}